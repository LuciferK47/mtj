# -*- coding: utf-8 -*-
"""edgd1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zUVkhD5hjwcASaVJXb-6AKHmoY-DUapi
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os
import glob
import random
from PIL import Image
from concurrent.futures import ProcessPoolExecutor, as_completed
import time
from skimage.metrics import structural_similarity as ssim
from scipy import ndimage
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# Set matplotlib backend and style
plt.style.use('default')
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = 'white'

# Load Kaggle Brain Tumor Dataset
def load_kaggle_brain_tumor_dataset(dataset_path="brain-tumor-mri-dataset", num_samples=5):
    """
    Load brain tumor images from Kaggle dataset.
    Dataset: https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri
    """
    images = []
    categories = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']

    if not os.path.exists(dataset_path):
        print(f"⚠ Dataset path '{dataset_path}' not found. Checking current directory...")
        potential_paths = [f for f in os.listdir('.') if os.path.isdir(f) and 'brain-tumor' in f.lower()]
        if potential_paths:
            dataset_path = potential_paths[0]
            print(f"✓ Found dataset at: {dataset_path}")
        else:
            print(f"⚠ No dataset folder found. Listing directory contents: {os.listdir('.')}")
            print("Falling back to synthetic images...")
            return create_synthetic_dataset(num_samples)

    for split in ['Training', 'Testing']:
        split_path = os.path.join(dataset_path, split)

        if not os.path.exists(split_path):
            print(f"⚠ {split} folder not found in {dataset_path}. Skipping...")
            continue

        for category in categories:
            category_path = os.path.join(split_path, category)

            if not os.path.exists(category_path):
                print(f"⚠ {category} folder not found in {split_path}. Skipping...")
                continue

            image_files = glob.glob(os.path.join(category_path, '*.jpg')) + \
                         glob.glob(os.path.join(category_path, '*.jpeg')) + \
                         glob.glob(os.path.join(category_path, '*.png'))

            print(f"Debug: Found {len(image_files)} images in {category_path}: {image_files[:5]}...")

            if len(image_files) > num_samples:
                image_files = random.sample(image_files, num_samples)

            for img_path in image_files:
                try:
                    img = Image.open(img_path).convert('L')
                    img = img.resize((256, 256), Image.Resampling.LANCZOS)
                    img_array = np.array(img)
                    img_array = cv2.equalizeHist(img_array)
                    source_info = f"{split}/{category}/{os.path.basename(img_path)}"
                    images.append((img_array, category, source_info))
                except Exception as e:
                    print(f"Error loading {img_path}: {e}")
                    continue

    if not images:
        print("⚠ No images found in Kaggle dataset. Creating synthetic images...")
        return create_synthetic_dataset(num_samples)

    print(f"✓ Loaded {len(images)} images from Kaggle dataset")
    return images

def create_synthetic_dataset(num_samples=5):
    """Create synthetic brain tumor images as fallback."""
    images = []
    categories = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']

    for category in categories:
        for i in range(num_samples):
            synthetic_img = create_synthetic_medical_image(category_type=category)
            source_info = f"Synthetic/{category}/sample_{i+1}.png"
            images.append((synthetic_img, category, source_info))

    return images

def create_synthetic_medical_image(size=256, category_type='glioma_tumor'):
    """Creates high-quality synthetic brain tumor image."""
    image = np.zeros((size, size), dtype=np.uint8)
    x, y = np.meshgrid(np.linspace(0, 1, size), np.linspace(0, 1, size))

    background = 120 + 25 * np.sin(6 * np.pi * x) * np.cos(6 * np.pi * y)
    background += 20 * np.random.normal(0, 1, (size, size))

    center_x, center_y = size//2, size//2
    for i in range(size):
        for j in range(size):
            dist_center = np.sqrt((i - center_x)**2 + (j - center_y)**2)
            if dist_center < 40:
                background[i, j] += 40

    if category_type == 'glioma_tumor':
        tumor_x, tumor_y = size//2 + 30, size//2 - 20
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - tumor_x)**2 + (j - tumor_y)**2)
                if dist < 30:
                    enhancement = 90 * np.exp(-dist/20) * (1 + 0.3 * np.random.random())
                    background[i, j] = min(255, background[i, j] + enhancement)

    elif category_type == 'meningioma_tumor':
        tumor_x, tumor_y = size//2 + 25, size//2 - 15
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - tumor_x)**2 + (j - tumor_y)**2)
                if dist < 20:
                    enhancement = 70 * np.exp(-dist/12)
                    background[i, j] = min(255, background[i, j] + enhancement)

    elif category_type == 'pituitary_tumor':
        tumor_x, tumor_y = size//2, size//2 + 10
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - tumor_x)**2 + (j - tumor_y)**2)
                if dist < 15:
                    enhancement = 60 * np.exp(-dist/10)
                    background[i, j] = min(255, background[i, j] + enhancement)

    for angle in np.linspace(0, 2*np.pi, 8):
        for r in range(80, 120):
            x_pos = int(center_x + r * np.cos(angle))
            y_pos = int(center_y + r * np.sin(angle))
            if 0 <= x_pos < size and 0 <= y_pos < size:
                background[x_pos, y_pos] += 30

    image = np.clip(background, 0, 255)
    return image.astype(np.uint8)

def bit_plane_decomposition(image):
    """Perform bit plane decomposition."""
    if len(image.shape) > 2:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    if image.dtype != np.uint8:
        image = image.astype(np.uint8)

    planes = []
    for bit in range(7, -1, -1):
        plane = np.bitwise_and(np.right_shift(image, bit), 1).astype(np.uint8) * 255
        planes.append(plane)

    return planes

def load_medical_image_robust(image_type=1):
    """Load medical image with robust error handling."""
    try:
        dataset_images = load_kaggle_brain_tumor_dataset(num_samples=1)
        if dataset_images:
            image_array, category, source_info = dataset_images[0]
            return image_array, f"{category} - {source_info}"
        else:
            synthetic_img = create_synthetic_medical_image(category_type='glioma_tumor')
            return synthetic_img, "Synthetic Brain Tumor (Dataset not found)"
    except Exception as e:
        print(f"Error loading medical image: {e}")
        synthetic_img = create_synthetic_medical_image(category_type='glioma_tumor')
        return synthetic_img, "Synthetic Brain Tumor (Dataset not found)"

def calculate_edge_quality_metrics(detected_edges, reference_edges=None, original_image=None):
    """Calculate quality metrics for edge detection."""
    metrics = {}
    if detected_edges.max() > 1:
        detected_edges = (detected_edges > 0).astype(np.uint8)

    total_pixels = detected_edges.size
    edge_pixels = np.sum(detected_edges > 0)
    metrics['edge_density'] = edge_pixels / total_pixels if total_pixels > 0 else 0
    metrics['edge_pixel_count'] = edge_pixels

    if original_image is not None:
        edge_mask = detected_edges > 0
        if np.any(edge_mask) and np.any(~edge_mask):
            edge_intensities = original_image[edge_mask]
            non_edge_intensities = original_image[~edge_mask]
            if len(edge_intensities) > 0 and len(non_edge_intensities) > 0:
                metrics['contrast_ratio'] = (np.mean(edge_intensities) + 1e-8) / (np.mean(non_edge_intensities) + 1e-8)
            else:
                metrics['contrast_ratio'] = 1.0
        else:
            metrics['contrast_ratio'] = 1.0
    else:
        metrics['contrast_ratio'] = 1.0

    if reference_edges is not None:
        detected_binary = (detected_edges > 0).astype(np.uint8)
        reference_binary = (reference_edges > 0).astype(np.uint8)

        if detected_binary.shape != reference_binary.shape:
            min_h = min(detected_binary.shape[0], reference_binary.shape[0])
            min_w = min(detected_binary.shape[1], reference_binary.shape[1])
            detected_binary = detected_binary[:min_h, :min_w]
            reference_binary = reference_binary[:min_h, :min_w]

        tp = np.sum((detected_binary == 1) & (reference_binary == 1))
        fp = np.sum((detected_binary == 1) & (reference_binary == 0))
        fn = np.sum((detected_binary == 0) & (reference_binary == 1))
        tn = np.sum((detected_binary == 0) & (reference_binary == 0))

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0

        metrics.update({
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'accuracy': accuracy
        })

        try:
            metrics['ssim'] = ssim(detected_binary, reference_binary, data_range=1)
        except:
            metrics['ssim'] = 0.0
    else:
        metrics.update({
            'precision': 0.0,
            'recall': 0.0,
            'f1_score': 0.0,
            'accuracy': 0.0,
            'ssim': 0.0
        })

    return metrics

def improved_mtj_edge_detection(binary_image, kernel_size=3):
    """
    Enhanced MTJ edge detection with optimized 4x4 kernel.
    Changes:
    - Updated 4x4 kernel weights: center=8, inner ring=2 for better balance.
    - Increased 4x4 threshold multiplier to 0.8 to reduce noise.
    - Used 3x3 median filter for 4x4 kernel to preserve fine edges.
    - Fixed Otsu thresholding by converting convolved image to 8-bit.
    - Improved fallback method with Sobel-based edge detection.
    """
    height, width = binary_image.shape
    edge_output = np.zeros((height, width), dtype=np.uint8)

    binary_image = (binary_image > 0).astype(np.uint8)

    if kernel_size == 2:
        kernel = np.array([[-1, 1], [1, -1]], dtype=np.float32)
    elif kernel_size == 3:
        kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=np.float32)
    else:  # kernel_size == 4
        kernel = np.array([
            [-1, -1, -1, -1],
            [-1,  2,  2, -1],
            [-1,  2,  8, -1],
            [-1, -1, -1, -1]
        ], dtype=np.float32)
        kernel = kernel / np.sum(np.abs(kernel))

    try:
        img_float = binary_image.astype(np.float32)
        convolved = cv2.filter2D(img_float, -1, kernel)

        threshold_factor = 0.8 if kernel_size == 4 else 0.5
        if kernel_size == 4:
            # Normalize convolved image to [0, 255] for Otsu thresholding
            convolved_norm = cv2.normalize(np.abs(convolved), None, 0, 255, cv2.NORM_MINMAX)
            convolved_8u = convolved_norm.astype(np.uint8)
            _, otsu_threshold = cv2.threshold(convolved_8u, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            threshold = max(otsu_threshold * 0.5, np.std(convolved) * threshold_factor)
        else:
            threshold = np.std(convolved) * threshold_factor

        edge_output = (np.abs(convolved) > threshold).astype(np.uint8) * 255

        if kernel_size == 4:
            edge_output = cv2.medianBlur(edge_output, 3)
            edge_output = cv2.morphologyEx(edge_output, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))

        edge_count = np.sum(edge_output > 0)
        print(f"Debug: {kernel_size}x{kernel_size} kernel - Edge count: {edge_count}, Threshold: {threshold:.2f}")
    except Exception as e:
        print(f"Convolution failed, using fallback Sobel-based method: {e}")
        # Improved fallback: Use Sobel edge detection
        sobel_x = cv2.Sobel(binary_image, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(binary_image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobel_x**2 + sobel_y**2)
        sobel_norm = cv2.normalize(sobel_mag, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        _, edge_output = cv2.threshold(sobel_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        edge_count = np.sum(edge_output > 0)
        print(f"Debug: {kernel_size}x{kernel_size} kernel (fallback) - Edge count: {edge_count}")

    return edge_output

def parallel_mtj_edge_detection(binary_image, kernel_size=3, num_processes=2):
    """Parallel processing with realistic energy and timing measurements."""
    start_time = time.time()

    edge_output = improved_mtj_edge_detection(binary_image, kernel_size)

    processing_time = time.time() - start_time

    energy_per_op = {2: 0.8e-9, 3: 1.2e-9, 4: 2.0e-9}
    pixels_processed = binary_image.size
    operations_per_pixel = kernel_size * kernel_size + 3
    total_operations = pixels_processed * operations_per_pixel

    estimated_energy = energy_per_op.get(kernel_size, 1.2e-9) * total_operations

    min_processing_time = 0.0001
    actual_processing_time = max(processing_time, min_processing_time)

    stats = {
        'total_energy': estimated_energy,
        'total_latency': actual_processing_time,
        'total_operations': total_operations,
        'kernel_size': kernel_size,
        'energy_per_operation': estimated_energy / total_operations if total_operations > 0 else 0,
        'pixels_processed': pixels_processed,
        'operations_per_pixel': operations_per_pixel,
        'throughput': pixels_processed / actual_processing_time if actual_processing_time > 0 else 0
    }

    return edge_output, stats

def comprehensive_mtj_comparison(medical_image, kernel_sizes=[2, 3, 4], use_parallel=True):
    """Comprehensive comparison of MTJ edge detection."""
    results = {}
    print("Performing bit plane decomposition...")
    bit_planes = bit_plane_decomposition(medical_image)

    print("Generating reference edges with Canny...")
    sigma = 0.33
    median_val = np.median(medical_image)
    lower_thresh = int(max(0, (1.0 - sigma) * median_val))
    upper_thresh = int(min(255, (1.0 + sigma) * median_val))
    canny_edges = cv2.Canny(medical_image, lower_thresh, upper_thresh)

    for kernel_size in kernel_sizes:
        print(f"Processing kernel size {kernel_size}x{kernel_size}...")
        kernel_results = {
            'kernel_size': kernel_size,
            'edge_images': [],
            'statistics': [],
            'quality_metrics': []
        }

        for plane_idx in range(min(3, len(bit_planes))):
            try:
                if use_parallel:
                    edge_image, stats = parallel_mtj_edge_detection(
                        bit_planes[plane_idx], kernel_size=kernel_size)
                else:
                    edge_image = improved_mtj_edge_detection(
                        bit_planes[plane_idx], kernel_size=kernel_size)
                    stats = {'kernel_size': kernel_size, 'total_energy': 0, 'total_latency': 0}

                quality = calculate_edge_quality_metrics(
                    edge_image, reference_edges=canny_edges, original_image=medical_image)

                kernel_results['edge_images'].append(edge_image)
                kernel_results['statistics'].append(stats)
                kernel_results['quality_metrics'].append(quality)

            except Exception as e:
                print(f"Error processing plane {plane_idx} for kernel {kernel_size}: {e}")
                dummy_edge = np.zeros_like(bit_planes[plane_idx])
                dummy_stats = {'kernel_size': kernel_size, 'total_energy': 0, 'total_latency': 0}
                dummy_quality = calculate_edge_quality_metrics(dummy_edge)
                kernel_results['edge_images'].append(dummy_edge)
                kernel_results['statistics'].append(dummy_stats)
                kernel_results['quality_metrics'].append(dummy_quality)

        if kernel_results['edge_images']:
            combined_edge = kernel_results['edge_images'][0].copy()
            for img in kernel_results['edge_images'][1:]:
                combined_edge = cv2.bitwise_or(combined_edge, img)
        else:
            combined_edge = np.zeros_like(medical_image)

        final_quality = calculate_edge_quality_metrics(
            combined_edge, reference_edges=canny_edges, original_image=medical_image)

        kernel_results['combined_edge'] = combined_edge
        kernel_results['final_quality'] = final_quality

        if kernel_results['statistics']:
            total_energy = sum(s.get('total_energy', 0) for s in kernel_results['statistics'])
            total_latency = sum(s.get('total_latency', 0) for s in kernel_results['statistics'])
            total_operations = sum(s.get('total_operations', medical_image.size) for s in kernel_results['statistics'])
            avg_throughput = np.mean([s.get('throughput', 0) for s in kernel_results['statistics']])

            f1_score = final_quality.get('f1_score', 0.001)
            energy_uj = total_energy * 1e6
            energy_efficiency = f1_score / max(energy_uj, 0.001)
            latency_ms = total_latency * 1000
            speed_efficiency = f1_score / max(latency_ms, 0.001)
            overall_efficiency = np.sqrt(energy_efficiency * speed_efficiency)

            kernel_results['aggregate_stats'] = {
                'total_energy': total_energy,
                'total_latency': total_latency,
                'total_operations': total_operations,
                'avg_throughput': avg_throughput,
                'energy_efficiency': energy_efficiency,
                'speed_efficiency': speed_efficiency,
                'overall_efficiency': overall_efficiency
            }

        results[f'kernel_{kernel_size}x{kernel_size}'] = kernel_results

    canny_quality = calculate_edge_quality_metrics(canny_edges, original_image=medical_image)
    results['canny_reference'] = {
        'edge_image': canny_edges,
        'quality_metrics': canny_quality
    }

    return results

def print_detailed_analysis(results, image_info=""):
    """Print detailed analysis of edge detection results."""
    print("\n" + "="*80)
    print(f"COMPREHENSIVE MTJ EDGE DETECTION ANALYSIS - BRAIN TUMOR\nImage: {image_info}")
    print("="*80)

    print("\n📊 QUALITY METRICS COMPARISON:")
    print("-" * 70)
    print(f"{'Kernel':<12} {'F1-Score':<10} {'Precision':<10} {'Recall':<10} {'SSIM':<8} {'Edge Density':<12}")
    print("-" * 70)

    kernel_sizes = [2, 3, 4]
    best_kernel = {'name': 'None', 'f1': 0}

    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results:
            quality = results[key]['final_quality']
            f1 = quality.get('f1_score', 0)
            precision = quality.get('precision', 0)
            recall = quality.get('recall', 0)
            ssim_val = quality.get('ssim', 0)
            edge_density = quality.get('edge_density', 0)
            print(f"{kernel_size}x{kernel_size:<7} {f1:<10.3f} {precision:<10.3f} {recall:<10.3f} {ssim_val:<8.3f} {edge_density:<12.4f}")

            if f1 > best_kernel['f1']:
                best_kernel = {'name': f'{kernel_size}x{kernel_size}', 'f1': f1}

    if 'canny_reference' in results:
        canny_quality = results['canny_reference']['quality_metrics']
        canny_edge_density = canny_quality.get('edge_density', 0)
        print(f"{'Canny':<12} {'1.000':<10} {'Ref':<10} {'Ref':<10} {'1.000':<8} {canny_edge_density:<12.4f}")

    print(f"\n🏆 Best Quality Performance: {best_kernel['name']} (F1-Score: {best_kernel['f1']:.3f})")

    print("\n⚡ ENERGY AND PERFORMANCE ANALYSIS:")
    print("-" * 85)
    print(f"{'Kernel':<12} {'Energy (μJ)':<12} {'Latency (ms)':<13} {'Operations':<12} {'Throughput (MP/s)':<16}")
    print("-" * 85)

    best_energy = {'kernel': 'None', 'efficiency': 0}
    best_speed = {'kernel': 'None', 'efficiency': 0}
    best_overall = {'kernel': 'None', 'efficiency': 0}

    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results and 'aggregate_stats' in results[key]:
            stats = results[key]['aggregate_stats']
            energy_uj = stats['total_energy'] * 1e6
            latency_ms = stats['total_latency'] * 1000
            operations = stats['total_operations']
            throughput_mps = stats['avg_throughput'] / 1e6
            print(f"{kernel_size}x{kernel_size:<10} {energy_uj:<12.3f} {latency_ms:<13.2f} {operations:<12,} {throughput_mps:<16.2f}")

            if stats['energy_efficiency'] > best_energy['efficiency']:
                best_energy = {'kernel': f'{kernel_size}x{kernel_size}', 'efficiency': stats['energy_efficiency']}
            if stats['speed_efficiency'] > best_speed['efficiency']:
                best_speed = {'kernel': f'{kernel_size}x{kernel_size}', 'efficiency': stats['speed_efficiency']}
            if stats['overall_efficiency'] > best_overall['efficiency']:
                best_overall = {'kernel': f'{kernel_size}x{kernel_size}', 'efficiency': stats['overall_efficiency']}

    print(f"\n⚡ Most Energy Efficient: {best_energy['kernel']} (Efficiency: {best_energy['efficiency']:.6f})")
    print(f"🚀 Fastest Processing: {best_speed['kernel']} (Efficiency: {best_speed['efficiency']:.4f})")
    print(f"🎯 Best Overall: {best_overall['kernel']} (Efficiency: {best_overall['efficiency']:.6f})")

    print("\n🎯 DETAILED EFFICIENCY ANALYSIS:")
    print("-" * 85)
    print(f"{'Kernel':<12} {'Energy Eff':<12} {'Speed Eff':<12} {'Overall Eff':<12} {'Quality Score':<14}")
    print("-" * 85)

    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results and 'aggregate_stats' in results[key]:
            quality = results[key]['final_quality']
            stats = results[key]['aggregate_stats']
            f1 = quality.get('f1_score', 0)
            energy_eff = stats['energy_efficiency']
            speed_eff = stats['speed_efficiency']
            overall_eff = stats['overall_efficiency']
            print(f"{kernel_size}x{kernel_size:<10} {energy_eff:<12.6f} {speed_eff:<12.4f} {overall_eff:<12.6f} {f1:<14.3f}")

    print("\n📊 BRAIN TUMOR ANALYSIS INSIGHTS:")
    print("-" * 60)
    print("🔬 Edge Detection Effectiveness for Brain Tumor Detection:")
    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results:
            quality = results[key]['final_quality']
            edge_density = quality.get('edge_density', 0)
            contrast_ratio = quality.get('contrast_ratio', 1.0)
            f1 = quality.get('f1_score', 0)
            print(f"\n{kernel_size}x{kernel_size} Kernel Analysis:")
            print(f"  • Edge Density: {edge_density:.4f} - {'High (captures fine details)' if edge_density > 0.15 else 'Moderate (good balance)' if edge_density > 0.05 else 'Low (major structures only)'}")
            print(f"  • Contrast Ratio: {contrast_ratio:.3f} - {'Excellent contrast' if contrast_ratio > 1.2 else 'Good contrast' if contrast_ratio > 1.05 else 'Limited contrast enhancement'}")
            print(f"  • Medical Suitability: {'Excellent for tumor detection' if f1 > 0.7 else 'Good for tumor identification' if f1 > 0.5 else 'Suitable for screening' if f1 > 0.3 else 'Requires optimization'}")

    if 'kernel_3x3' in results and 'kernel_4x4' in results:
        f1_3x3 = results['kernel_3x3']['final_quality'].get('f1_score', 0)
        f1_4x4 = results['kernel_4x4']['final_quality'].get('f1_score', 0)
        if f1_4x4 > f1_3x3:
            print(f"\n✅ Note: 4x4 kernel outperforms 3x3 kernel (F1: {f1_4x4:.3f} vs {f1_3x3:.3f})")
            print("  Improvements achieved through:")
            print("  • Optimized kernel weights (center=8, inner ring=2)")
            print("  • Fixed Otsu thresholding with 8-bit conversion")
            print("  • Refined post-processing with 3x3 median filtering")
            print("  • Improved fallback with Sobel-based edge detection")
        else:
            print(f"\n⚠ Note: 3x3 kernel still outperforms 4x4 kernel (F1: {f1_3x3:.3f} vs {f1_4x4:.3f})")
            print("  Possible reasons:")
            print("  • Tumor characteristics better matched to 3x3 kernel")
            print("  • Further tuning of 4x4 kernel needed (e.g., adjust threshold multiplier)")
            print("  • Consider additional preprocessing like CLAHE")

    print("\n💡 RECOMMENDATIONS:")
    print("-" * 60)
    recommendations = [
        f"1. For highest accuracy: Use {best_kernel['name']} kernel (F1: {best_kernel['f1']:.3f})",
        f"2. For energy efficiency: Use {best_energy['kernel']} kernel (Eff: {best_energy['efficiency']:.6f})",
        f"3. For speed: Use {best_speed['kernel']} kernel (Eff: {best_speed['efficiency']:.4f})",
        f"4. For balanced performance: Use {best_overall['kernel']} kernel (Eff: {best_overall['efficiency']:.6f})",
        "5. For critical brain tumor detection: Use multi-kernel ensemble approach",
        "6. Balance sensitivity and specificity for tumor screening",
        "7. Apply CLAHE pre-processing for better contrast"
    ]
    for rec in recommendations:
        print(rec)

    print("\n" + "="*80)

def create_comprehensive_visualization(results, medical_image, image_source="", save_path='mtj_brain_tumor_analysis.png'):
    """Create visualization of edge detection results."""
    plt.style.use('default')
    fig = plt.figure(figsize=(20, 14))
    fig.patch.set_facecolor('white')
    gs = gridspec.GridSpec(3, 6, hspace=0.4, wspace=0.3, height_ratios=[1, 0.8, 0.8], width_ratios=[1, 1, 1, 1, 1, 1])

    ax_orig = fig.add_subplot(gs[0, 0])
    ax_orig.imshow(medical_image, cmap='gray', aspect='equal')
    ax_orig.set_title(f'Original Brain Tumor Image\n({image_source})', fontweight='bold', fontsize=10)
    ax_orig.axis('off')

    ax_canny = fig.add_subplot(gs[0, 1])
    if 'canny_reference' in results:
        ax_canny.imshow(results['canny_reference']['edge_image'], cmap='gray', aspect='equal')
        ax_canny.set_title('Canny Reference', fontweight='bold', fontsize=10)
    ax_canny.axis('off')

    kernel_sizes = [2, 3, 4]
    colors = ['red', 'blue', 'green']
    for i, kernel_size in enumerate(kernel_sizes):
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results:
            ax_mtj = fig.add_subplot(gs[0, i + 2])
            ax_mtj.imshow(results[key]['combined_edge'], cmap='gray', aspect='equal')
            f1 = results[key]['final_quality'].get('f1_score', 0)
            ax_mtj.set_title(f'MTJ {kernel_size}x{kernel_size}\nF1: {f1:.3f}', fontweight='bold', color=colors[i], fontsize=10)
            ax_mtj.axis('off')

    ax_quality = fig.add_subplot(gs[1, :3])
    metrics_to_plot = ['f1_score', 'precision', 'recall', 'edge_density']
    x_pos = np.arange(len(metrics_to_plot))
    width = 0.25
    for i, kernel_size in enumerate(kernel_sizes):
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results:
            values = [results[key]['final_quality'].get(metric, 0) for metric in metrics_to_plot]
            ax_quality.bar(x_pos + i * width, values, width, label=f'{kernel_size}x{kernel_size}', color=colors[i], alpha=0.7)
    ax_quality.set_xlabel('Quality Metrics', fontsize=10)
    ax_quality.set_ylabel('Score', fontsize=10)
    ax_quality.set_title('Quality Metrics Comparison', fontweight='bold', fontsize=11)
    ax_quality.set_xticks(x_pos + width)
    ax_quality.set_xticklabels([m.replace('_', ' ').title() for m in metrics_to_plot], rotation=15)
    ax_quality.legend(fontsize=9)
    ax_quality.grid(True, alpha=0.3)
    ax_quality.set_ylim(0, 1.1)

    ax_perf = fig.add_subplot(gs[1, 3:])
    energy_data = []
    latency_data = []
    efficiency_data = []
    labels = []
    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results and 'aggregate_stats' in results[key]:
            energy_data.append(results[key]['aggregate_stats']['total_energy'] * 1e6)
            latency_data.append(results[key]['aggregate_stats']['total_latency'] * 1000)
            efficiency_data.append(results[key]['aggregate_stats']['energy_efficiency'])
            labels.append(f'{kernel_size}x{kernel_size}')
    if energy_data and latency_data:
        ax_perf2 = ax_perf.twinx()
        x_positions = np.arange(len(labels))
        bars1 = ax_perf.bar(x_positions - 0.2, energy_data, width=0.35, label='Energy (μJ)', color='orange', alpha=0.7)
        bars2 = ax_perf2.bar(x_positions + 0.2, latency_data, width=0.35, label='Latency (ms)', color='purple', alpha=0.7)
        ax_perf.set_xlabel('Kernel Size', fontsize=10)
        ax_perf.set_ylabel('Energy (μJ)', color='orange', fontsize=10)
        ax_perf2.set_ylabel('Latency (ms)', color='purple', fontsize=10)
        ax_perf.set_title('Energy and Latency Comparison', fontweight='bold', fontsize=11)
        ax_perf.set_xticks(x_positions)
        ax_perf.set_xticklabels(labels)
        for bar, value in zip(bars1, energy_data):
            ax_perf.text(bar.get_x() + bar.get_width()/2, value + max(energy_data)*0.02, f'{value:.3f}', ha='center', va='bottom', fontsize=8)
        for bar, value in zip(bars2, latency_data):
            ax_perf2.text(bar.get_x() + bar.get_width()/2, value + max(latency_data)*0.02, f'{value:.2f}', ha='center', va='bottom', fontsize=8)

    ax_eff = fig.add_subplot(gs[2, :3])
    if efficiency_data:
        bars = ax_eff.bar(labels, efficiency_data, color=['red', 'blue', 'green'], alpha=0.7)
        ax_eff.set_xlabel('Kernel Size', fontsize=10)
        ax_eff.set_ylabel('Energy Efficiency (F1/μJ)', fontsize=10)
        ax_eff.set_title('Energy Efficiency Comparison', fontweight='bold', fontsize=11)
        ax_eff.grid(True, alpha=0.3)
        for bar, value in zip(bars, efficiency_data):
            ax_eff.text(bar.get_x() + bar.get_width()/2, value + max(efficiency_data)*0.02, f'{value:.6f}', ha='center', va='bottom', fontsize=8)

    ax_table = fig.add_subplot(gs[2, 3:])
    ax_table.axis('off')
    table_data = []
    headers = ['Kernel', 'F1-Score', 'Precision', 'Recall', 'Energy (μJ)', 'Latency (ms)', 'Efficiency']
    for kernel_size in kernel_sizes:
        key = f'kernel_{kernel_size}x{kernel_size}'
        if key in results:
            quality = results[key]['final_quality']
            row = [f'{kernel_size}x{kernel_size}']
            row.append(f"{quality.get('f1_score', 0):.3f}")
            row.append(f"{quality.get('precision', 0):.3f}")
            row.append(f"{quality.get('recall', 0):.3f}")
            if 'aggregate_stats' in results[key]:
                stats = results[key]['aggregate_stats']
                row.append(f"{stats.get('total_energy', 0) * 1e6:.3f}")
                row.append(f"{stats.get('total_latency', 0) * 1000:.2f}")
                row.append(f"{stats.get('energy_efficiency', 0):.6f}")
            else:
                row.extend(['N/A', 'N/A', 'N/A'])
            table_data.append(row)
    if table_data:
        table = ax_table.table(cellText=table_data, colLabels=headers, cellLoc='center', loc='center', bbox=[0, 0.2, 1, 0.6])
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1, 1.5)
        for i in range(len(headers)):
            table[(0, i)].set_facecolor('#4CAF50')
            table[(0, i)].set_text_props(weight='bold', color='white')
        efficiency_scores = [float(row[6]) if row[6] != 'N/A' else 0 for row in table_data]
        if efficiency_scores:
            best_idx = np.argmax(efficiency_scores) + 1
            for j in range(len(headers)):
                table[(best_idx, j)].set_facecolor('#FFE082')

    plt.suptitle('Enhanced MTJ Edge Detection Analysis for Brain Tumor Images', fontsize=16, fontweight='bold', y=0.95)
    try:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        print(f"✓ Visualization saved as: {save_path}")
    except Exception as e:
        print(f"Warning: Could not save visualization: {e}")
    plt.tight_layout()
    plt.show()

def calculate_energy_efficiency(quality_metrics, energy_stats):
    """Calculate energy efficiency."""
    try:
        f1_score = quality_metrics.get('f1_score', 0.001)
        total_energy_uj = energy_stats.get('total_energy', 1e-6) * 1e6
        efficiency = f1_score / max(total_energy_uj, 0.001)
        return efficiency
    except Exception as e:
        print(f"Warning: Efficiency calculation error: {e}")
        return 0.0

def export_results_to_csv(results, filename='mtj_brain_tumor_results.csv'):
    """Export results to CSV."""
    try:
        data = []
        for kernel_key, kernel_data in results.items():
            if kernel_key.startswith('kernel_'):
                kernel_size = kernel_key.split('_')[1]
                quality = kernel_data['final_quality']
                stats = kernel_data.get('aggregate_stats', {})
                row = {
                    'Kernel_Size': kernel_size,
                    'F1_Score': quality.get('f1_score', 0),
                    'Precision': quality.get('precision', 0),
                    'Recall': quality.get('recall', 0),
                    'SSIM': quality.get('ssim', 0),
                    'Edge_Density': quality.get('edge_density', 0),
                    'Energy_uJ': stats.get('total_energy', 0) * 1e6,
                    'Latency_ms': stats.get('total_latency', 0) * 1000,
                    'Energy_Efficiency': stats.get('energy_efficiency', 0)
                }
                data.append(row)
        df = pd.DataFrame(data)
        df.to_csv(filename, index=False)
        print(f"✓ Results exported to {filename}")
    except Exception as e:
        print(f"⚠ CSV export error: {e}")

def main():
    """Main execution function."""
    print("🏥 Enhanced MTJ Edge Detection for Brain Tumor Image Analysis")
    print("="*65)
    print("📊 Using Kaggle Brain Tumor MRI Dataset")
    print("   Dataset: https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri")
    print("   Categories: Glioma Tumor, Meningioma Tumor, No Tumor, Pituitary Tumor")

    all_results = {}
    img_type = 'brain_tumor'
    print(f"\n📸 Processing Brain Tumor Images...")
    print("-" * 50)

    try:
        dataset_path = "brain-tumor-mri-dataset"
        if not os.path.exists(dataset_path):
            print(f"⚠ Dataset path '{dataset_path}' not found. Ensure dataset is unzipped.")
            print("  Falling back to synthetic images...")
        medical_image, source_info = load_medical_image_robust(1)
        print(f"✓ Successfully loaded image: {source_info}")
        print(f"  Image size: {medical_image.shape}")

        print(f"\n🔬 Performing MTJ edge detection analysis...")
        print("  Testing kernel sizes: 2x2, 3x3, 4x4")
        start_time = time.time()
        results = comprehensive_mtj_comparison(medical_image, kernel_sizes=[2, 3, 4], use_parallel=True)

        for kernel_key, kernel_data in results.items():
            if kernel_key.startswith('kernel_') and 'aggregate_stats' in kernel_data:
                kernel_data['aggregate_stats']['energy_efficiency'] = calculate_energy_efficiency(
                    kernel_data['final_quality'], kernel_data['aggregate_stats'])

        analysis_time = time.time() - start_time
        print(f"  ✓ Analysis completed in {analysis_time:.2f} seconds")

        all_results[img_type] = {
            'results': results,
            'image': medical_image,
            'source': source_info,
            'processing_time': analysis_time
        }

        print(f"\n📊 Generating visualization...")
        try:
            create_comprehensive_visualization(
                results, medical_image, image_source=f"Brain Tumor - {source_info}",
                save_path='mtj_brain_tumor_analysis.png')
            print(f"  ✓ Visualization saved as: mtj_brain_tumor_analysis.png")
        except Exception as e:
            print(f"  ⚠ Visualization error: {e}")

        print(f"\n📋 Detailed Analysis Report for Brain Tumor:")
        print("="*60)
        print_detailed_analysis(results, source_info)

        print(f"\n📈 Brain Tumor Analysis Summary:")
        print(f"   Processing time: {analysis_time:.2f} seconds")
        print(f"   Image dimensions: {medical_image.shape}")
        print(f"   Source: {source_info}")

        best_kernel = {'name': 'None', 'efficiency': 0, 'f1': 0}
        for kernel_size in [2, 3, 4]:
            key = f'kernel_{kernel_size}x{kernel_size}'
            if key in results and 'aggregate_stats' in results[key]:
                f1 = results[key]['final_quality'].get('f1_score', 0)
                efficiency = results[key]['aggregate_stats'].get('energy_efficiency', 0)
                if efficiency > best_kernel['efficiency']:
                    best_kernel = {'name': f'{kernel_size}x{kernel_size}', 'efficiency': efficiency, 'f1': f1}
        print(f"   Best kernel (efficiency): {best_kernel['name']} (Efficiency: {best_kernel['efficiency']:.6f}, F1: {best_kernel['f1']:.3f})")

    except Exception as e:
        print(f"⚠ Error processing brain tumor: {e}")
        import traceback
        traceback.print_exc()

    print(f"\n🎉 COMPLETE MTJ ANALYSIS FINISHED!")
    print("="*50)
    print(f"Total image types processed: {len(all_results)}")
    print(f"Kernel configurations tested: 3 (2x2, 3x3, 4x4)")
    print(f"Quality metrics calculated: 6 per configuration")
    print(f"Performance metrics: Energy, Latency, Efficiency (Fixed)")

    print(f"\n📁 Generated Files:")
    print(f"   • mtj_brain_tumor_analysis.png")
    print(f"\n💾 Exporting results...")
    try:
        if img_type in all_results:
            export_results_to_csv(all_results[img_type]['results'], 'mtj_brain_tumor_results.csv')
    except Exception as e:
        print(f"   ⚠ Could not export results: {e}")

    print(f"\n✅ Analysis complete! Check the generated files for detailed results.")
    print(f"\n🔧 Fixed Issues for 4x4 Kernel:")
    print(f"   • Adjusted kernel weights (center=8, inner ring=2) for better balance")
    print(f"   • Fixed Otsu thresholding by converting to 8-bit unsigned integer")
    print(f"   • Used 3x3 median filter to preserve fine edges")
    print(f"   • Improved fallback with Sobel-based edge detection")

    return all_results

if __name__ == "__main__":
    all_results = main()